{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sFjgQBaXPNwe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkA-RzgEPSBP",
    "outputId": "8717662d-7a56-4a60-d5c6-ed54f9571355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wego1x3k) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>training_accuracy</td><td>▁▇█</td></tr><tr><td>training_loss</td><td>█▂▁</td></tr><tr><td>validation_loss</td><td>█▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>training_accuracy</td><td>89.33333</td></tr><tr><td>training_loss</td><td>0.29001</td></tr><tr><td>validation_loss</td><td>0.33084</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">restful-music-2</strong> at: <a href='https://wandb.ai/vedemin-agh-university/aml_lab1_1/runs/wego1x3k' target=\"_blank\">https://wandb.ai/vedemin-agh-university/aml_lab1_1/runs/wego1x3k</a><br/> View project at: <a href='https://wandb.ai/vedemin-agh-university/aml_lab1_1' target=\"_blank\">https://wandb.ai/vedemin-agh-university/aml_lab1_1</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241118_221858-wego1x3k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wego1x3k). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\creep\\Documents\\GitHub\\mldevops_exercise\\wandb\\run-20241118_222059-g8hkyve9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vedemin-agh-university/aml_lab1_1/runs/g8hkyve9' target=\"_blank\">rose-moon-3</a></strong> to <a href='https://wandb.ai/vedemin-agh-university/aml_lab1_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vedemin-agh-university/aml_lab1_1' target=\"_blank\">https://wandb.ai/vedemin-agh-university/aml_lab1_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vedemin-agh-university/aml_lab1_1/runs/g8hkyve9' target=\"_blank\">https://wandb.ai/vedemin-agh-university/aml_lab1_1/runs/g8hkyve9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vedemin-agh-university/aml_lab1_1/runs/g8hkyve9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x22a26cc2610>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"aml_lab1_1\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"FashionMNIST\",\n",
    "    \"epochs\": 50,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3EWbkwLePOrE"
   },
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x.view(-1, 28 * 28))\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class CnnNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CnnNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VtpEYyxRQlrC"
   },
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAKcjCWcSioy"
   },
   "outputs": [],
   "source": [
    "def GetModelAndResults(train_dataset, test_dataset, type=\"linear\", epochs=50):\n",
    "  train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "  test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "  if type == \"linear\":\n",
    "    model = SimpleNet()\n",
    "  elif type == \"cnn\":\n",
    "    model = CnnNet()\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "        \n",
    "        # Compute accuracy (optional)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "    training_loss /= len(train_loader)  # Average training loss\n",
    "    training_accuracy = total_correct / total_samples * 100\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            validation_loss += loss.item()\n",
    "    \n",
    "    validation_loss /= len(test_loader)  # Average validation loss\n",
    "\n",
    "    # Log metrics to wandb\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"training_loss\": training_loss,\n",
    "        \"validation_loss\": validation_loss,\n",
    "        \"training_accuracy\": training_accuracy\n",
    "    })\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Training Loss: {training_loss:.4f}, Validation Loss: {validation_loss:.4f}, Training Accuracy: {training_accuracy:.2f}%\")\n",
    "\n",
    "  # Evaluation\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "      for images, labels in test_loader:\n",
    "          outputs = model(images)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "\n",
    "  accuracy = 100 * correct / total\n",
    "  print(f'Accuracy: {accuracy}%')\n",
    "  # Save your script file as an artifact\n",
    "  artifact = wandb.Artifact(\"training_script\", type=\"code\")\n",
    "  artifact.add_file(\"AML_Lab1.py\")\n",
    "  wandb.log_artifact(artifact)\n",
    "  wandb.finish()\n",
    "  return model, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFlQsKW0Sn0d",
    "outputId": "570d1c2c-fae6-406b-c363-2d72b60be144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss: 0.4638, Validation Loss: 0.3865, Training Accuracy: 82.86%\n",
      "Epoch 2: Training Loss: 0.3376, Validation Loss: 0.3685, Training Accuracy: 87.32%\n",
      "Epoch 3: Training Loss: 0.3138, Validation Loss: 0.3478, Training Accuracy: 88.35%\n",
      "Epoch 4: Training Loss: 0.2964, Validation Loss: 0.3415, Training Accuracy: 88.87%\n",
      "Epoch 5: Training Loss: 0.2870, Validation Loss: 0.3259, Training Accuracy: 89.13%\n",
      "Epoch 6: Training Loss: 0.2796, Validation Loss: 0.3347, Training Accuracy: 89.44%\n",
      "Epoch 7: Training Loss: 0.2702, Validation Loss: 0.3255, Training Accuracy: 89.91%\n",
      "Epoch 8: Training Loss: 0.2655, Validation Loss: 0.3231, Training Accuracy: 90.04%\n",
      "Epoch 9: Training Loss: 0.2611, Validation Loss: 0.3431, Training Accuracy: 90.24%\n",
      "Epoch 10: Training Loss: 0.2576, Validation Loss: 0.3335, Training Accuracy: 90.42%\n",
      "Epoch 11: Training Loss: 0.2517, Validation Loss: 0.3494, Training Accuracy: 90.58%\n",
      "Epoch 12: Training Loss: 0.2478, Validation Loss: 0.3317, Training Accuracy: 90.83%\n",
      "Epoch 13: Training Loss: 0.2463, Validation Loss: 0.3529, Training Accuracy: 90.71%\n",
      "Epoch 14: Training Loss: 0.2407, Validation Loss: 0.3316, Training Accuracy: 91.12%\n",
      "Epoch 15: Training Loss: 0.2355, Validation Loss: 0.3507, Training Accuracy: 91.25%\n",
      "Epoch 16: Training Loss: 0.2339, Validation Loss: 0.3346, Training Accuracy: 91.20%\n",
      "Epoch 17: Training Loss: 0.2319, Validation Loss: 0.3469, Training Accuracy: 91.37%\n",
      "Epoch 18: Training Loss: 0.2315, Validation Loss: 0.4031, Training Accuracy: 91.44%\n",
      "Epoch 19: Training Loss: 0.2239, Validation Loss: 0.3579, Training Accuracy: 91.69%\n",
      "Epoch 20: Training Loss: 0.2182, Validation Loss: 0.3939, Training Accuracy: 91.88%\n",
      "Accuracy: 88.75%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>training_accuracy</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇█▇████</td></tr><tr><td>training_loss</td><td>█▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▇▅▃▃▁▂▁▁▃▂▃▂▄▂▃▂▃█▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>training_accuracy</td><td>91.88167</td></tr><tr><td>training_loss</td><td>0.21823</td></tr><tr><td>validation_loss</td><td>0.39393</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-moon-3</strong> at: <a href='https://wandb.ai/vedemin-agh-university/aml_lab1_1/runs/g8hkyve9' target=\"_blank\">https://wandb.ai/vedemin-agh-university/aml_lab1_1/runs/g8hkyve9</a><br/> View project at: <a href='https://wandb.ai/vedemin-agh-university/aml_lab1_1' target=\"_blank\">https://wandb.ai/vedemin-agh-university/aml_lab1_1</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241118_222059-g8hkyve9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb.init(\n",
    "#     project=\"aml_lab1_1\",\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.01,\n",
    "#     \"architecture\": \"linear\",\n",
    "#     \"dataset\": \"FashionMNIST\",\n",
    "#     \"epochs\": 50,\n",
    "#     }\n",
    "# )\n",
    "# linearModel, linearAccuracy = GetModelAndResults(train_dataset, test_dataset, type=\"linear\", epochs=50)\n",
    "\n",
    "# wandb.init(\n",
    "#     project=\"aml_lab1_1\",\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.01,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"FashionMNIST\",\n",
    "#     \"epochs\": 50,\n",
    "#     }\n",
    "# )\n",
    "cnnModel, cnnAccuracy = GetModelAndResults(train_dataset, test_dataset, type=\"cnn\", epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehd7NmijWfW6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
